%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\usepackage[utf8x]{inputenc}

\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage[dontkeepoldnames]{sphinx}

\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}

\addto\extrasenglish{\def\pageautorefname{page}}



\usepackage{enumitem}

\title{Loom Deployment Guide}
\date{Apr 07, 2018}
\release{0.7.0}
\author{Veritas Technologies LLC}
\newcommand{\sphinxlogo}{\sphinxincludegraphics{loom.png}\par}
\renewcommand{\releasename}{Release}
\makeindex

\begin{document}

\maketitle
\sphinxtableofcontents
\phantomsection\label{\detokenize{loom_installation_guide::doc}}


\begin{sphinxShadowBox}
\begin{itemize}
\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id9}}{\hyperref[\detokenize{loom_installation_guide:introduction-to-loom-deployment}]{\sphinxcrossref{Introduction to Loom Deployment}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id10}}{\hyperref[\detokenize{loom_installation_guide:loom-deployment-models}]{\sphinxcrossref{Loom: Deployment Models}}}
\begin{itemize}
\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id11}}{\hyperref[\detokenize{loom_installation_guide:on-premise-deployment}]{\sphinxcrossref{On Premise Deployment}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id12}}{\hyperref[\detokenize{loom_installation_guide:public-cloud-deployment}]{\sphinxcrossref{Public Cloud Deployment}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id13}}{\hyperref[\detokenize{loom_installation_guide:hybrid-cloud-deployment}]{\sphinxcrossref{Hybrid Cloud Deployment}}}

\end{itemize}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id14}}{\hyperref[\detokenize{loom_installation_guide:installation-prerequisites}]{\sphinxcrossref{Installation Prerequisites}}}
\begin{itemize}
\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id15}}{\hyperref[\detokenize{loom_installation_guide:planning-preparation}]{\sphinxcrossref{Planning \& Preparation}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id16}}{\hyperref[\detokenize{loom_installation_guide:system-requirements}]{\sphinxcrossref{System Requirements}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id17}}{\hyperref[\detokenize{loom_installation_guide:verify-dependencies}]{\sphinxcrossref{Verify Dependencies}}}

\end{itemize}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id18}}{\hyperref[\detokenize{loom_installation_guide:bootstrapping-loom}]{\sphinxcrossref{Bootstrapping Loom}}}
\begin{itemize}
\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id19}}{\hyperref[\detokenize{loom_installation_guide:on-boarding-multi-tier-applications-on-loom}]{\sphinxcrossref{On-boarding multi-tier Applications on Loom}}}

\end{itemize}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id20}}{\hyperref[\detokenize{loom_installation_guide:loom-cloud-deployment}]{\sphinxcrossref{Loom: Cloud Deployment}}}
\begin{itemize}
\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id21}}{\hyperref[\detokenize{loom_installation_guide:azure-deployment-guide}]{\sphinxcrossref{Azure Deployment Guide}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id22}}{\hyperref[\detokenize{loom_installation_guide:overview}]{\sphinxcrossref{Overview}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id23}}{\hyperref[\detokenize{loom_installation_guide:oracle-deployment}]{\sphinxcrossref{Oracle Deployment}}}

\end{itemize}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id24}}{\hyperref[\detokenize{loom_installation_guide:loom-on-premise-deployment}]{\sphinxcrossref{Loom On-Premise Deployment}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id25}}{\hyperref[\detokenize{loom_installation_guide:loom-hybrid-deployment}]{\sphinxcrossref{Loom Hybrid Deployment}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id26}}{\hyperref[\detokenize{loom_installation_guide:loom-de-installation-procedure}]{\sphinxcrossref{Loom: De-installation Procedure}}}
\begin{itemize}
\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id27}}{\hyperref[\detokenize{loom_installation_guide:service-shutdown}]{\sphinxcrossref{Service Shutdown}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id28}}{\hyperref[\detokenize{loom_installation_guide:de-installing-component-a}]{\sphinxcrossref{De-installing component A}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id29}}{\hyperref[\detokenize{loom_installation_guide:upgrading-loom}]{\sphinxcrossref{Upgrading Loom}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id30}}{\hyperref[\detokenize{loom_installation_guide:cleanup-scripts}]{\sphinxcrossref{Cleanup Scripts}}}

\end{itemize}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id31}}{\hyperref[\detokenize{loom_installation_guide:deployment-troubleshooting-guide}]{\sphinxcrossref{Deployment Troubleshooting Guide}}}
\begin{itemize}
\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id32}}{\hyperref[\detokenize{loom_installation_guide:resolving-basic-loom-deployment-issues}]{\sphinxcrossref{Resolving Basic Loom deployment issues}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id33}}{\hyperref[\detokenize{loom_installation_guide:loom-service-patching}]{\sphinxcrossref{Loom Service Patching}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id34}}{\hyperref[\detokenize{loom_installation_guide:troubleshooting-loom-networking-issues}]{\sphinxcrossref{Troubleshooting Loom networking issues}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id35}}{\hyperref[\detokenize{loom_installation_guide:control-plane-issues}]{\sphinxcrossref{Control plane Issues}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id36}}{\hyperref[\detokenize{loom_installation_guide:data-plane-issues}]{\sphinxcrossref{Data plane Issues}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id37}}{\hyperref[\detokenize{loom_installation_guide:message-flow-between-data-plane-control-plane}]{\sphinxcrossref{Message flow between data plane/control plane}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id38}}{\hyperref[\detokenize{loom_installation_guide:tenant-deployment-issues}]{\sphinxcrossref{Tenant deployment issues}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id39}}{\hyperref[\detokenize{loom_installation_guide:security-issues}]{\sphinxcrossref{Security Issues}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id40}}{\hyperref[\detokenize{loom_installation_guide:issues-related-to-loom-logs-access-logs}]{\sphinxcrossref{Issues related to Loom logs, Access logs}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id41}}{\hyperref[\detokenize{loom_installation_guide:moving-to-different-availability-set}]{\sphinxcrossref{Moving to different availability set}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id42}}{\hyperref[\detokenize{loom_installation_guide:issues-related-to-sluggish-loom-application-response}]{\sphinxcrossref{Issues related to sluggish Loom Application response}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id43}}{\hyperref[\detokenize{loom_installation_guide:issues-related-to-loom-metrics}]{\sphinxcrossref{Issues related to Loom Metrics}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id44}}{\hyperref[\detokenize{loom_installation_guide:issues-related-to-system-load}]{\sphinxcrossref{Issues related to System Load}}}

\end{itemize}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id45}}{\hyperref[\detokenize{loom_installation_guide:deployment-faq}]{\sphinxcrossref{Deployment FAQ}}}
\begin{itemize}
\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id46}}{\hyperref[\detokenize{loom_installation_guide:question-a-related-to-any-type-of-loom-deployment}]{\sphinxcrossref{Question A: Related to any type of Loom deployment}}}

\end{itemize}

\end{itemize}
\end{sphinxShadowBox}


\chapter{Introduction to Loom Deployment}
\label{\detokenize{loom_installation_guide:introduction-to-loom-deployment}}\label{\detokenize{loom_installation_guide:installation-guide-rst}}\label{\detokenize{loom_installation_guide:loom-installation-deployment-guide}}
This section will cover introduction of Loom Installation and Deployment Methodology as seen by an external user. A user refers to DevOps Admin or Enterprise Admin in charge of deploying Loom Platform.

It will also cover how this guide is organized.  After introduction section, there is a section on Deployment models describing different ways in which Loom can be deployed for use in an enterprise. Next, it will cover deployment and install process for each method in detail. The last section is about general troubleshooting and FAQ for overall Loom Platform deployment and install process.  In addition to the generic troubleshooting section, there will be per deployment model specific troubleshooting and FAQ guides that will cover topics specific to a particular deployment model.


\sphinxstrong{See also:}


This is a \sphinxstylestrong{PLACEHOLDER} content.



Please note, this is placeholder text according to current outline.  We will refine the content in subsequent iterations as UK folks plug in the specifics for say Cloud based deployment.


\bigskip\hrule\bigskip



\chapter{Loom: Deployment Models}
\label{\detokenize{loom_installation_guide:loom-deployment-models}}\label{\detokenize{loom_installation_guide:ing-dep-models-mcdmp-rst}}
Loom can be deployed as per the enterprise needs either on premise, or in a private cloud, or public cloud, or a hybrid environment.  The platform offers flexible deployment on-premise either on bare metal servers or virtual machines.

Other details TBD in consultation with Platform team.


\section{On Premise Deployment}
\label{\detokenize{loom_installation_guide:on-premise-deployment}}\begin{itemize}
\item {} 
Bare Metal Server

\item {} 
Virtual Machine

\end{itemize}


\section{Public Cloud Deployment}
\label{\detokenize{loom_installation_guide:public-cloud-deployment}}\begin{itemize}
\item {} 
Azure

\item {} 
Oracle

\item {} 
AWS

\item {} 
Others

\end{itemize}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{Cloud-Provider}
&
Deployment Guide Reference
\\
\hline
\sphinxstylestrong{Azure}
&
Refer to {\hyperref[\detokenize{loom_installation_guide:file-cloud-azure-dep-guide}]{\sphinxcrossref{\DUrole{std,std-ref}{Azure Deployment Guide}}}}
\\
\hline
\sphinxstylestrong{Oracle}
&
TBD
\\
\hline
\sphinxstylestrong{AWS}
&
TBD
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\section{Hybrid Cloud Deployment}
\label{\detokenize{loom_installation_guide:hybrid-cloud-deployment}}
Loom can also be deployed as a hybrid cloud. The first version of the product does not support this model.  This section will be updated in subsequent releases of Loom.


\bigskip\hrule\bigskip



\chapter{Installation Prerequisites}
\label{\detokenize{loom_installation_guide:installation-prerequisites}}
This section will contain the software required to deploy Loom. This is a generic section not specific to any deployment model. Deployment Model specific pre-requisites will be covered in the respective sections.

For e.g., to bring up the control plane what are the software and setup needed.
See details here: \sphinxhref{https://jira.community.veritas.com/browse/IMP-964?jql=project\%20\%3D\%20IMP\%20AND\%20status\%20\%3D\%20Open\%20AND\%20text\%20~\%20\%22Document\%22}{Issue in Jira (IMP-964)}


\section{Planning \& Preparation}
\label{\detokenize{loom_installation_guide:planning-preparation}}
Placeholder Outline of Planning \& Preparation Section


\section{System Requirements}
\label{\detokenize{loom_installation_guide:system-requirements}}
For latest Loom System Requirements, refer to \sphinxhref{http://10.67.141.149/shaloo/aggr/pform-ugdocs/html/loom\_getting\_started\_guide.html\#content-platform-tech-specs}{\DUrole{xref,std,std-ref}{Platform Technical Specifications Section}}.


\section{Verify Dependencies}
\label{\detokenize{loom_installation_guide:verify-dependencies}}\begin{itemize}
\item {} 
Loom Deployment requires several Open Source Software components.

\item {} 
See the \DUrole{xref,std,std-ref}{ing\_loom\_all\_dep\_list} utilized by Loom Platform and Loom Applications.

\end{itemize}


\bigskip\hrule\bigskip



\chapter{Bootstrapping Loom}
\label{\detokenize{loom_installation_guide:bootstrapping-loom}}
In the previous sections of this Installation Guide, we covered various options available to an enterprise for Loom Platform deployment and pre-requisites for the same.

This section explains how Loom Platform itself is bootstrapped in various deployment models. Besides that, it lists workflows on how various Loom components and services are instantiated. Next, it covers how to on board an end-to-end multi-tiered application on Loom Platform.

At a conceptual level, there are 4 stages of Loom Platform deployment that need to be completed by the Platform, Partner and Tenant Admin before the end user can begin using various features offered by Platform and its Apps such as Visibility and Classification.
\begin{itemize}
\item {} 
\sphinxstylestrong{STAGE1:} As a first step, the Platform and its components need to be downloaded and initiated (for an on-premise deployment). In case of a Cloud based deployment, this first step is usually carried out either by Veritas or one of its Partners. During this phase, infrastructure components including persistent databases, micro-services comprising of the Platform and Control Plane constituents are instantiated.

\item {} 
\sphinxstylestrong{STAGE2:} Next, the Data Planes need to be setup for every tenant or customer organization and user accounts created in the context of each tenant.  This can be done only by tenant Admin, so Loom Platform deployment Admin must setup Partner Admin accounts (if a Partner such as Cloud Provider is hosting Loom Platform) or create respective Tenant Admin to carry out Data Plane orchestration. The Data Plane setup requires credentials that are internal to the Tenant organization - for e.g., Azure access credentials, AWS customer credentials etc. Besides this, the Tenant Admin also needs to create user accounts and assign roles such as Storage/IT Admin, end users, and others. The Platform Admin or the Partner Admin is also required to define the enterprise wide Data Access policies to enable data data scans, audits and tracking for various enterprise data assets.

\item {} 
\sphinxstylestrong{STAGE3:} After, User account definition and Data Plane configuration, the Tenant Admin or assigned user with Storage/IT Admin role can plug in different data sources within the organization that need to be analyzed and scanned for gaining data insights and visibility. This may require access to various filers, cloud storage and other data sources within the enterprise. (Question:  Does that mean that there may be \sphinxstylestrong{unknown} data sources that are being managed and expenses made for storage that may not even be known to an enterprise? There is no auto detection of filers / storage sources in Loom Platform - right?) The

\item {} 
\sphinxstylestrong{STAGE4:} Once users are defined, policies and data sources configured, end users can begin using the Platform and access Platform Apps that are deployed in their context.  Note, not all Platform Apps may be visible to all tenant accounts.  The default ones accessible to all include Platform UI App, Visibility \& Classification App. Also, not all user roles may be allowed to view all kinds of enterprise information. For e.g., only a certain kinds of privileged users may have access to all PII stored within the enterprise.  Loom Platform can scan and tag all data provided it to via policies, data sources and other filters and classify information based on filters and tags.

\end{itemize}

Content-TBD
Add a high level picture with 4 blobs and arrows pointing from first stage to the fourth one.
Jason-help-needed!

Figure below goes to the next level of detail describing Loom Platform bootstrapping at a conceptual level.  Different color highlight different stages.  You can see various Platform Admin roles and personas that carry out each of these steps to ensure Platform services are up and running for end users to begin interacting with it.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.75]{{mcdmp_bootstrap}.png}
\caption{Figure: Stages of Loom Platform Bootstrapping Process}\label{\detokenize{loom_installation_guide:id2}}\end{figure}


\sphinxstrong{See also:}


This is a \sphinxstylestrong{DOC-CONTRIB} Request

This section contains placeholder for content that requires shared contribution by Loom dev / owner personnel. As part of Loom Deployment section, we need to add the step by step instructions on how an end user would actually deploy Loom.  Use the following JIRA EPIC pointers for more information and user stories regarding the same.
\begin{itemize}
\item {} 
User Onboarding section: Refer to \sphinxhref{http://jira.community.veritas.com/browse/IMP-887/}{Jira 887}

\item {} 
Control Plane Bootstrapping: Refer to \sphinxhref{http://jira.community.veritas.com/browse/IMP-966/}{Jira 966}

\item {} 
How to deploy a data plane (on-premise): Refer to \sphinxhref{http://jira.community.veritas.com/browse/IMP-993/}{Jira 993}

\item {} 
How to register a deployed data plane with control plane: Refer to \sphinxhref{http://jira.community.veritas.com/browse/IMP-995/}{Jira 995}

\end{itemize}




\section{On-boarding multi-tier Applications on Loom}
\label{\detokenize{loom_installation_guide:on-boarding-multi-tier-applications-on-loom}}
Describe how a multi-tier application can on-board Loom Platform.  This includes third party applications such as ??? (find list from Platform team). What about in-built apps (if any)? Choosing and installing via Marketplace?
\begin{itemize}
\item {} 
Generic 3 tier apps

\item {} 
Specific App \textendash{} from Marketplace

\item {} 
3rd party apps

\item {} 
SaaS Hosted Apps

\end{itemize}


\bigskip\hrule\bigskip



\chapter{Loom: Cloud Deployment}
\label{\detokenize{loom_installation_guide:loom-cloud-deployment}}
\sphinxstylestrong{Introduction}

Veritas Loom Cloud Deployment Model is designed to work on any public cloud provider such as Microsoft Azure, Amazon AWS, Google GCP, Oracle Cloud, IBM Cloud and other cloud providers.  In the very first release, Loom is available as a pre-deployed service hosted on Microsoft Azure.  In future releases, Veritas Partners will be able to deploy Loom themselves on a cloud of their choice.

\sphinxstylestrong{Overview}

The following figure gives a high level overview of a typical Loom Cloud deployment.  It comprises of a starter VM that helps to jump-start a Kubernetes cluster with requisite Loom services that are needed to bring up various Loom capabilities
such as managing Loom Users, managing connectivity to various enterprise content repositories, administration of Loom Deployment, managing data classification jobs and their status, tracking data accesses, setting up of enterprise specific data policies and more.

\begin{sphinxadmonition}{note}{Note:}
To be updated

This section will contain image / diagram / figures explaining how a Loom Cloud deployment is done, various components and where each is deployed.  How the enterprise / MSP can set up Loom on cloud, which components to interact with and more.
Looking up to Branislav / Adam to provide a high level sketch that can be added here.

Note, this diagram will be generic to any cloud deployment.  Specific cloud deployments will be covered in individual deployment guides dedicated to each supported cloud provider.
\end{sphinxadmonition}


\bigskip\hrule\bigskip



\section{Azure Deployment Guide}
\label{\detokenize{loom_installation_guide:file-cloud-azure-dep-guide}}\label{\detokenize{loom_installation_guide:azure-deployment-guide}}
This guide covers the design and implementation details of deploying Veritas Loom on Microsoft Azure cloud. It is intended for DevOps personnel that are entrusted with deploying Loom for Veritas or its Partner Enterprise. The very first release of Veritas Loom is \sphinxstyleemphasis{only} available as a SaaS deployment hosted on Microsoft Azure and managed by Veritas.  In future, Veritas Partners can bring up their own Loom SaaS deployment on Microsoft Azure and onboard customer organizations. For deploying Loom on other cloud providers, refer to Cloud Provider specific Loom deployment Guide.

The following sections cover Loom deployment on Microsoft Azure and how to bring up all the services to ensure deployment status is healthy and ready for further usage.  For details on how to use Loom, refer to the Loom User Getting Started Guide.

Loom Azure Deployment comprises of four key areas:  Cloud Configuration, Loom Infrastructure Setup, High Availability(HA) and Cluster Deployment, Security and Access Control and other Azure specific deployment details. The last section of this guide addresses some of the common issues faced during Loom deployment on Microsoft Azure and troubleshooting tips.


\bigskip\hrule\bigskip



\section{Overview}
\label{\detokenize{loom_installation_guide:content-azure-dep-oview}}\label{\detokenize{loom_installation_guide:overview}}
The figure below captures a very high level diagram of a typical Loom SaaS deployment on Microsoft Azure based cloud infrastructure.

\begin{sphinxadmonition}{caution}{Caution:}
The overview section is under the process of refinement / review and updates.

The figure below is based on the one provided by Engineering DevOps on Confluence Page titled \sphinxhref{https://confluence.community.veritas.com/x/PjPFBw}{Azure Topology}. The internal confluence reference will be eliminated from the final draft of this guide, once the details are crystallized and ready for sharing with external customers.
\end{sphinxadmonition}


\bigskip\hrule\bigskip


\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=1.0]{{azure-dep-fig}.png}
\caption{Figure: Loom (Alpha2) Control Plane Deployment Topology on Microsoft Azure}\label{\detokenize{loom_installation_guide:id3}}\end{figure}

\begin{sphinxadmonition}{caution}{Caution:}
The figure below shows the Loom Azure SaaS Data Plane Deployment Details.  Parking it here for the next refresh cycle of the Loom Deployment Guide.
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=1.0]{{azure-dep-dp-fig}.png}
\caption{Figure: Loom (Alpha2) Data Plane Deployment Topology on Microsoft Azure}\label{\detokenize{loom_installation_guide:id4}}\end{figure}


\bigskip\hrule\bigskip



\subsection{Azure Configuration}
\label{\detokenize{loom_installation_guide:azure-configuration}}\begin{enumerate}
\item {} 
Identification of region/s
\begin{itemize}
\item {} 
Number of Availability set required and define how different component uses it.
\begin{itemize}
\item {} 
Rack id : will this be used in no SQL Engines?

\end{itemize}

\end{itemize}

\item {} 
Identification of Azure account

\item {} 
Identification of regions to be deployed

\item {} 
Identification of domain and sub-domain name(if required)
\begin{itemize}
\item {} 
DNS

\item {} 
Static IP required?

\end{itemize}

\item {} 
VPN connection across regions

\item {} 
Deployment Topology
\begin{itemize}
\item {} 
Azure \textbar{} Oracle

\end{itemize}

\item {} 
General
\begin{itemize}
\item {} 
Network connectivity
\begin{itemize}
\item {} 
Subnets
\begin{itemize}
\item {} 
Database

\item {} 
DMZ zone

\item {} 
CP/DP communication

\end{itemize}

\item {} 
VNET peering

\end{itemize}

\item {} 
Traffic flow

\item {} 
Bandwidth/latency

\item {} 
Bastion server - Management server

\item {} 
WAF for all external network calls

\end{itemize}

\item {} 
Network flow diagram and port access across system boundaries
\begin{itemize}
\item {} 
UI accessing LB

\item {} 
Communication from CP to DP, Ports opened

\item {} 
Communication from DP to CP, Ports opened

\item {} 
Network flow: tenant isolation depicted diagram

\item {} 
IPSec or HTTPS/SSL from CP to DP

\end{itemize}

\item {} 
Firewall/NAT services in front of load balancer
\begin{itemize}
\item {} 
Learning, Blocking, slow connection

\end{itemize}

\item {} 
Front end load balancer : Azure\textbar{} oracle load balancer
\begin{itemize}
\item {} 
SSL offloading  - Terminate at load balancer?

\item {} 
Data at motion security consideration has to be finalized and updated

\item {} 
NGINX  HA

\end{itemize}

\end{enumerate}


\bigskip\hrule\bigskip



\subsection{Loom Infrastructure Setup}
\label{\detokenize{loom_installation_guide:loom-infrastructure-setup}}
Following is the suggested outline for this sub-section.  Information related to these topics need to be fleshed out for Loom Infrastructure Setup in the context of Azure deployment.


\subsubsection{Deploying infra services}
\label{\detokenize{loom_installation_guide:deploying-infra-services}}\begin{enumerate}
\item {} 
DMZ zone
\begin{itemize}
\item {} 
Application gateway

\item {} 
Firewall
\begin{itemize}
\item {} 
which firewall and its configuration management

\item {} 
Different Security group

\item {} 
Different subnet

\end{itemize}

\item {} 
Management
\begin{itemize}
\item {} 
Bastion server
\begin{itemize}
\item {} 
Different Security Group

\item {} 
Different subnet

\end{itemize}

\end{itemize}

\end{itemize}

\item {} 
Infra components
\begin{itemize}
\item {} 
Cassandra
\begin{itemize}
\item {} 
Partitioning strategy

\item {} 
Adding a node

\item {} 
Decommissioning node

\item {} 
Re-balancing

\item {} 
Database backup/recovery

\item {} 
version update

\end{itemize}

\item {} 
Elastic search
\begin{itemize}
\item {} 
Master and data node deployment

\item {} 
Add a node

\item {} 
De-commission node

\item {} 
Identifying bottle necks, Split brain, Data loss, reconciliation

\item {} 
Version update

\end{itemize}

\item {} 
Postgres
\begin{itemize}
\item {} 
Master/Slave

\item {} 
Virtual IP/DNS
\begin{itemize}
\item {} 
Switching between Master/slave

\end{itemize}

\item {} 
Capacity planning with data growth

\item {} 
version update

\end{itemize}

\item {} 
K8 cluster
\begin{itemize}
\item {} 
Integration with Veritas LDAP user ?

\item {} 
Namespace design

\item {} 
Across region deployment (if required)??
\begin{itemize}
\item {} 
VPC peering kind of in azure

\item {} 
Availability set

\end{itemize}

\end{itemize}

\item {} 
Kafka
\begin{itemize}
\item {} 
Ports opened

\item {} 
Partition

\item {} 
Number of Brokers
\begin{itemize}
\item {} 
Addition

\item {} 
Decommission

\end{itemize}

\end{itemize}

\item {} 
RabbitMQ
\begin{itemize}
\item {} 
Federation required across region(if required)

\item {} 
SSL

\end{itemize}

\item {} 
System crashes
\begin{itemize}
\item {} 
Handling of VM/EC2 crashes
\begin{itemize}
\item {} 
Volume strategy

\item {} 
recovery

\end{itemize}

\item {} 
Corruption of volumes/recovery mechanism

\end{itemize}

\item {} 
DR/BR
\begin{itemize}
\item {} 
Database backup
\begin{itemize}
\item {} 
Incremental

\end{itemize}

\item {} 
Geographic Disaster

\end{itemize}

\end{itemize}

\end{enumerate}


\bigskip\hrule\bigskip



\subsection{HA / Cluster Deployment}
\label{\detokenize{loom_installation_guide:ha-cluster-deployment}}
This is the suggested outline for HA /Cluster Deployment section in case of Azure Deployment.
\begin{itemize}
\item {} 
Define availability set

\item {} 
Define number of nodes that will be supported by default and adding incremental node

\item {} 
VPN connection across regions
\begin{itemize}
\item {} 
IPSec or HTTPS/SSL from CP to DP

\item {} 
Artifactory server access to upgrade

\end{itemize}

\end{itemize}


\bigskip\hrule\bigskip



\subsection{Security \& Access Control}
\label{\detokenize{loom_installation_guide:security-access-control}}
Here is a recommended outline for Security and Access Control Setup in Azure Deployment scenario of MCDM Platform (Loom). We need to flesh out this section along with diagrams / figures.
\begin{itemize}
\item {} 
Access control to deployed system
\begin{itemize}
\item {} 
Via Bastion server

\end{itemize}
\begin{itemize}
\item {} 
Least privileges

\end{itemize}
\begin{itemize}
\item {} 
Key management and rotation policy

\item {} 
Audit log

\end{itemize}

\item {} 
Security
\begin{itemize}
\item {} 
Handle - when security is comprised
\begin{itemize}
\item {} 
Patch update/services

\item {} 
recovery

\end{itemize}

\item {} 
Intrusion detection system - Firewall
\begin{itemize}
\item {} 
SQL injection prevention, XSS attacks

\item {} 
WAF ?

\item {} 
Define golden configuration

\end{itemize}

\item {} 
OS hardening
\begin{itemize}
\item {} 
Docker user and access control
\begin{itemize}
\item {} 
Restriction File access, encrypted volume

\end{itemize}

\item {} 
Host firewall

\end{itemize}

\item {} 
Network traffic
\begin{itemize}
\item {} 
Network ACL, Security groups, Routing table on Azure/oracle/AWS
\begin{itemize}
\item {} 
Golden configuration

\end{itemize}

\item {} 
List all ports that are white listed

\end{itemize}

\item {} 
Auditing/Incident notification
\begin{itemize}
\item {} 
Integration with messaging/email

\end{itemize}

\item {} 
Key management - Data at motion, Data at rest
\begin{itemize}
\item {} 
Encryption

\end{itemize}

\end{itemize}

\end{itemize}


\bigskip\hrule\bigskip



\subsection{Miscellaneous Setups and Azure Tuning for Loom}
\label{\detokenize{loom_installation_guide:miscellaneous-setups-and-azure-tuning-for-loom}}
This section covers other miscellaneous configuration settings and tuning required to ensure that Veritas Loom is successfully up and running normally in Microsoft Azure Cloud.  Need help from Adam and Branislav to populate this section.
\textasciitilde{}


\bigskip\hrule\bigskip



\subsection{Azure Deployment Troubleshooting Guide}
\label{\detokenize{loom_installation_guide:azure-deployment-troubleshooting-guide}}
Loom Deployment on Microsoft Azure Cloud might face certain deployment issues. This guide contains some of the frequently encountered issues and fixes, tips on how to solve them to attain a healthy Loom Deployment status.

TBD - Need help from Branislav, Dinesh, Adam and others to populate this section.


\bigskip\hrule\bigskip



\section{Oracle Deployment}
\label{\detokenize{loom_installation_guide:oracle-deployment}}
TBD


\bigskip\hrule\bigskip



\chapter{Loom On-Premise Deployment}
\label{\detokenize{loom_installation_guide:loom-on-premise-deployment}}\label{\detokenize{loom_installation_guide:ing-com-on-prem-install}}
This is not supported in the initial release.

This guide is a placeholder for now.  It will be covered once the functionality is added in Loom platform.


\bigskip\hrule\bigskip



\chapter{Loom Hybrid Deployment}
\label{\detokenize{loom_installation_guide:loom-hybrid-deployment}}
This mode of deployment is not supported in the initial release of Loom.

This Guide is a placeholder until this functionality is supported in Loom.


\bigskip\hrule\bigskip



\chapter{Loom: De-installation Procedure}
\label{\detokenize{loom_installation_guide:loom-de-installation-procedure}}
TBD


\section{Service Shutdown}
\label{\detokenize{loom_installation_guide:service-shutdown}}
TBD


\section{De-installing component A}
\label{\detokenize{loom_installation_guide:de-installing-component-a}}
TBD


\section{Upgrading Loom}
\label{\detokenize{loom_installation_guide:upgrading-loom}}
TBD


\section{Cleanup Scripts}
\label{\detokenize{loom_installation_guide:cleanup-scripts}}
TBD


\bigskip\hrule\bigskip



\chapter{Deployment Troubleshooting Guide}
\label{\detokenize{loom_installation_guide:ing-com-dep-trbs}}\label{\detokenize{loom_installation_guide:deployment-troubleshooting-guide}}
This guide lists down some of the key issues faced during Loom Deployment and provides useful tips and insights on how to address Loom Deployment issues.  The audience for this guide are the Loom Platform Admins, Loom Application developers and others trying to deploy Loom and its components.

\begin{sphinxadmonition}{warning}{Warning:}
The following content is primarily focused on Loom Deployment in SaaS Model on Microsoft Azure Cloud. This is the only supported deployment as of Loom Alpha releases.

In future, this guide may also contain information related to other kinds of Loom Deployment.  For details on different kinds of Loom Deployments see {\hyperref[\detokenize{loom_installation_guide:ing-dep-models-mcdmp-rst}]{\sphinxcrossref{\DUrole{std,std-ref}{Loom: Deployment Models}}}}.
\end{sphinxadmonition}

\begin{sphinxShadowBox}
\begin{itemize}
\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id47}}{\hyperref[\detokenize{loom_installation_guide:resolving-basic-loom-deployment-issues}]{\sphinxcrossref{Resolving Basic Loom deployment issues}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id48}}{\hyperref[\detokenize{loom_installation_guide:loom-service-patching}]{\sphinxcrossref{Loom Service Patching}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id49}}{\hyperref[\detokenize{loom_installation_guide:troubleshooting-loom-networking-issues}]{\sphinxcrossref{Troubleshooting Loom networking issues}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id50}}{\hyperref[\detokenize{loom_installation_guide:control-plane-issues}]{\sphinxcrossref{Control plane Issues}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id51}}{\hyperref[\detokenize{loom_installation_guide:data-plane-issues}]{\sphinxcrossref{Data plane Issues}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id52}}{\hyperref[\detokenize{loom_installation_guide:message-flow-between-data-plane-control-plane}]{\sphinxcrossref{Message flow between data plane/control plane}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id53}}{\hyperref[\detokenize{loom_installation_guide:tenant-deployment-issues}]{\sphinxcrossref{Tenant deployment issues}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id54}}{\hyperref[\detokenize{loom_installation_guide:security-issues}]{\sphinxcrossref{Security Issues}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id55}}{\hyperref[\detokenize{loom_installation_guide:issues-related-to-loom-logs-access-logs}]{\sphinxcrossref{Issues related to Loom logs, Access logs}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id56}}{\hyperref[\detokenize{loom_installation_guide:moving-to-different-availability-set}]{\sphinxcrossref{Moving to different availability set}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id57}}{\hyperref[\detokenize{loom_installation_guide:issues-related-to-sluggish-loom-application-response}]{\sphinxcrossref{Issues related to sluggish Loom Application response}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id58}}{\hyperref[\detokenize{loom_installation_guide:issues-related-to-loom-metrics}]{\sphinxcrossref{Issues related to Loom Metrics}}}

\item {} 
\phantomsection\label{\detokenize{loom_installation_guide:id59}}{\hyperref[\detokenize{loom_installation_guide:issues-related-to-system-load}]{\sphinxcrossref{Issues related to System Load}}}

\end{itemize}
\end{sphinxShadowBox}


\bigskip\hrule\bigskip



\section{Resolving Basic Loom deployment issues}
\label{\detokenize{loom_installation_guide:resolving-basic-loom-deployment-issues}}
This section lists some of the Loom deployment related issues faced in early builds, alpha1, alpha2 and how to resolve the same.


\subsection{How to begin Loom deployment troubleshooting?}
\label{\detokenize{loom_installation_guide:how-to-begin-loom-deployment-troubleshooting}}
The first step is to check the status of the \sphinxhref{http://10.67.141.149/shaloo/aggr/pform-ugdocs/html/mcdmp\_concepts.html\#def-term-planes}{Control And Data Planes} in a Loom deployment.

Following figures show all the pods in healthy state.  The first figure refers to a healthy control plane showing all the Loom pods that make up a Loom Control Plane.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=1.0]{{healthy_cp}.png}
\caption{Figure: Loom Control Plane - all pods are healthy in this figure.}\label{\detokenize{loom_installation_guide:id5}}\end{figure}

The figure below refers to a healthy data plane showing all the Loom pods that make up a Loom Data Plane.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=1.0]{{healthy_dp}.png}
\caption{Figure: Loom Data Plane - all pods are healthy in this figure.}\label{\detokenize{loom_installation_guide:id6}}\end{figure}


\subsection{Where to look for more details is a Pod is not healthy?}
\label{\detokenize{loom_installation_guide:where-to-look-for-more-details-is-a-pod-is-not-healthy}}
If a pod looks like it is not running properly the next step is to look at it’s log file using the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{kubectl} \PYG{n}{logs} \PYG{o}{\PYGZlt{}}\PYG{n}{podname}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{n}{n} \PYG{n}{platform}
\end{sphinxVerbatim}

Figure below shows the command and its output.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=1.0]{{pod_log}.png}
\caption{Figure: Examine Pod Log for details}\label{\detokenize{loom_installation_guide:id7}}\end{figure}


\subsection{How to determine which software version is deployed for each pod?}
\label{\detokenize{loom_installation_guide:how-to-determine-which-software-version-is-deployed-for-each-pod}}
If you want to check the version of a particular pod, use the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{helm} \PYG{n}{ls}
\end{sphinxVerbatim}

The figure below shows all services are at version B-2017122115 - apart from Airflow which has been patched to version B-2017122123.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=1.0]{{helm_ls}.png}
\caption{Figure: Examine Service version number deployed in pod}\label{\detokenize{loom_installation_guide:id8}}\end{figure}


\subsection{Looking for Dependency Health}
\label{\detokenize{loom_installation_guide:looking-for-dependency-health}}
If services that rely upon Postgres (Airflow, App Manager, KMS, Cluster Manager, IDM, Job Management) are failing it might be caused by a problem with the Postgres deployment on the persistent VM. Check to see if the databases are present by ssh’ing into the persistent VM and using psql to list the databases hosted on the server. The output should look similar to the following:

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=1.0]{{dep_check}.png}
\end{figure}

Figure: Examine Service Dependency for failures


\subsection{Loom Tenant Creation Issues}
\label{\detokenize{loom_installation_guide:loom-tenant-creation-issues}}
If you find that tenants are not being created properly (i.e. they never reach a state of ‘Active’ in the UI), the first thing to check is whether the create\_tenant dag has been triggered. Use port forwarding to map a local port (e.g. 8080) to port 8080 on the Airflow pod and use a web browser to view the Airflow UI using \sphinxurl{http://localhost:8080}. For e.g., use the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{kubectl} \PYG{n}{port}\PYG{o}{\PYGZhy{}}\PYG{n}{forward} \PYG{n}{pform}\PYG{o}{\PYGZhy{}}\PYG{n}{airflow}\PYG{o}{\PYGZhy{}}\PYG{n}{service}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{2073380254}\PYG{o}{\PYGZhy{}}\PYG{n}{bgff7} \PYG{l+m+mi}{8080}\PYG{p}{:}\PYG{l+m+mi}{8080} \PYG{o}{\PYGZhy{}}\PYG{n}{n} \PYG{n}{platform}
\end{sphinxVerbatim}

In the example below we can see that although Airflow indicates a data plane DAG run has taken place twice (one failed, one succeeded) no executions are listed against add\_tenant. So we know that the add tenant request never reached Airflow:

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=1.0]{{airflow_eg}.png}
\end{figure}

Figure: Examine Add Tenant DAG Execution Status

If a DAG run for create\_tenant has taken place then the log files for this may indicate a problem.
In this situation we know that a DAG run has not taken place. So the next step is to check the logs for cluster manager. Use the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{kubectl} \PYG{n}{logs} \PYG{o}{\PYGZlt{}}\PYG{n}{cluster} \PYG{n}{manager} \PYG{n}{pod} \PYG{n}{name}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{n}{n} \PYG{n}{platform}
\end{sphinxVerbatim}

In the figure below, notice the “CONTROL\_CLUSTER\_NOT\_FOUND” error. That needs further debugging on what went wrong with the cluster.

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=1.0]{{error_cls}.png}
\end{figure}

Figure: Tenant could not be created as there was cluster error


\subsection{Content source added but cannot view data in the Loom Application Dashboard}
\label{\detokenize{loom_installation_guide:content-source-added-but-cannot-view-data-in-the-loom-application-dashboard}}
If you have added a content source and are not seeing data in the visibility app you might want to check to see if jobs have been created in the database. To do this log in to the persistent VM via ssh (see above) and access Postgres setting the context to the JobsDB. In the select command below, substitute the tenantId with the tenantId of the tenant you are trouble-shooting:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} psql \PYGZhy{}d JobsDB \PYGZhy{}U CFUser
JobsDB=\PYGZgt{} select * from \PYGZdq{}JobsQueue\PYGZdq{} where \PYGZdq{}TenantId\PYGZdq{}=\PYGZsq{}3337b7fa\PYGZhy{}342f\PYGZhy{}4522\PYGZhy{}b62b\PYGZhy{}e4c36b1856cf\PYGZsq{};
\end{sphinxVerbatim}

You should see jobs of type DISCOVERY, SCAN and UPLOAD created for your tenant with statuses of CREATED, RUNNING or SUCCEEDED. There maybe multiple entries for each depending on the content source - e.g. for Box, a set of jobs will be created for each account that has access to the data.


\subsection{Kafka does not produce or consume any data, how to fix it?}
\label{\detokenize{loom_installation_guide:kafka-does-not-produce-or-consume-any-data-how-to-fix-it}}
On one of the recent builds we have seen an issue that after initial bootstrap Kafka may not be producing and consuming any data. This seems to be a timing issue during bootstrap. We do not have any specific logs or errors being thrown from Kafka server. Workaround for this issue would be running following 3 commands and wait until pods come up properly:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} kubectl \PYGZhy{}n platform delete pod pform\PYGZhy{}data\PYGZhy{}streaming\PYGZhy{}kafka\PYGZhy{}stfl\PYGZhy{}0
\PYGZdl{} kubectl \PYGZhy{}n platform delete pod pform\PYGZhy{}data\PYGZhy{}streaming\PYGZhy{}kafka\PYGZhy{}stfl\PYGZhy{}1\PYGZhy{}0
\PYGZdl{} kubectl \PYGZhy{}n platform delete pod pform\PYGZhy{}data\PYGZhy{}streaming\PYGZhy{}kafka\PYGZhy{}stfl\PYGZhy{}2\PYGZhy{}0
\end{sphinxVerbatim}

This will delete the pods only - not the deployment or service configuration.

Check that the pods start properly by using the get pods command (they will go through the normal cycle of ContainerCreating to Running).
After the pods have started log into Kafka on two different terminal sessions and then produce and consume data by using the following commands (remember to substitute the pod name with the one from your environment):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} kubectl \PYGZhy{}n platform exec  \PYGZhy{}it pform\PYGZhy{}data\PYGZhy{}streaming\PYGZhy{}kafka\PYGZhy{}stfl\PYGZhy{}0 sh

Producer:

sh\PYGZhy{}4.2\PYGZsh{} kafka\PYGZhy{}console\PYGZhy{}producer.sh \PYGZhy{}\PYGZhy{}broker\PYGZhy{}list pform\PYGZhy{}data\PYGZhy{}streaming\PYGZhy{}kafka\PYGZhy{}service:9093 \PYGZhy{}\PYGZhy{}topic INFRASTRUCTURE\PYGZus{}DISCOVERY
\PYGZlt{}Type Anything on the console and wait for 30 seconds. Than press ctrl+c \PYGZgt{}

Consumer:

sh\PYGZhy{}4.2\PYGZsh{} kafka\PYGZhy{}console\PYGZhy{}consumer.sh \PYGZhy{}\PYGZhy{}bootstrap\PYGZhy{}server pform\PYGZhy{}data\PYGZhy{}streaming\PYGZhy{}kafka\PYGZhy{}service:9093 \PYGZhy{}\PYGZhy{}topic INFRASTRUCTURE\PYGZus{}DISCOVERY \PYGZhy{}\PYGZhy{}from\PYGZhy{}beginning
\end{sphinxVerbatim}

You should see the characters you typed into the producer session appearing in the consumer session. If you don’t then this would suggest there is still a configuration issue with Kafka.


\section{Loom Service Patching}
\label{\detokenize{loom_installation_guide:loom-service-patching}}\begin{enumerate}
\item {} 
Quick patching Service for troubleshooting

Most of the Loom Services Docker images provide run command which start the service as part of container initialization process. The service starts with pid 1, and it becomes difficult to restart the service without bringing down the container (i.e., service pod).

During troubleshooting you may require to make some quick changes (log message, variable change or fix) and test it before committing the changes. The typical workflow in this case involves rebuilding the Docker image for the service and redeploying it again in Kubernetes. In an ideal deployment, as part of the run command of Docker image, we should install a package (dpkg) in the container. This makes it easy to restart the service without bringing down the container.

Following method can be used so save some time during troubleshooting of Loom Services and applying service patches. In short, what you need to do is use “Sleep infinity” as a Docker RUN command, which would start the container with root process (pid 1) in sleep.  This makes it easy to replace any jar /config information in this container.
\begin{itemize}
\item {} 
From your service directory edit the Dockerfile and change the run command to:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{sleep} \PYG{n}{infinity}
\end{sphinxVerbatim}

For e.g.,
\begin{quote}

CMD {[}“sleep”,”infinity”{]}
\end{quote}

\item {} 
Get the list of pods using the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{helm} \PYG{n}{ls}
\end{sphinxVerbatim}

\item {} 
Delete the service you wish to troubleshoot using the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{helm} \PYG{n}{delete} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{purge} \PYG{o}{\PYGZlt{}}\PYG{n}{service}\PYG{o}{\PYGZhy{}}\PYG{n}{name}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

\item {} 
Build the Docker image of the service using the edited Dockerfile (step 1) with different tag using the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
   docker build \textendash{}t \PYGZlt{}service\PYGZhy{}name\PYGZgt{}:\PYGZlt{}tag\PYGZgt{}

For e.g.,

   docker build \textendash{}t apps\PYGZhy{}classification\PYGZhy{}orchestrator:test
\end{sphinxVerbatim}

\item {} 
Login into the repository you want to push the image to using the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
    \PYG{n}{docker} \PYG{n}{login} \PYG{o}{\PYGZlt{}} \PYG{n}{repository}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{n}{u} \PYG{o}{\PYGZlt{}}\PYG{n}{username}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{n}{p} \PYG{o}{\PYGZlt{}}\PYG{n}{password}\PYG{o}{\PYGZgt{}}

\PYG{n}{For} \PYG{n}{e}\PYG{o}{.}\PYG{n}{g}\PYG{o}{.}\PYG{p}{,}

    \PYG{n}{docker} \PYG{n}{login} \PYG{n}{mcdmpdemoregistry}\PYG{o}{.}\PYG{n}{azurecr}\PYG{o}{.}\PYG{n}{io} \PYG{o}{\PYGZhy{}}\PYG{n}{u} \PYG{n}{test} \PYG{o}{\PYGZhy{}}\PYG{n}{p} \PYG{n}{test}
\end{sphinxVerbatim}

\item {} 
Tag the image with repository name using the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
    \PYG{n}{docker} \PYG{n}{tag} \PYG{o}{\PYGZlt{}}\PYG{n}{service}\PYG{o}{\PYGZhy{}}\PYG{n}{name}\PYG{o}{\PYGZgt{}}\PYG{p}{:}\PYG{o}{\PYGZlt{}}\PYG{n}{tag}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}} \PYG{n}{repository}\PYG{o}{\PYGZgt{}}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{service}\PYG{o}{\PYGZhy{}}\PYG{n}{name}\PYG{o}{\PYGZgt{}}\PYG{p}{:}\PYG{o}{\PYGZlt{}}\PYG{n}{tag}\PYG{o}{\PYGZgt{}}

\PYG{n}{For} \PYG{n}{e}\PYG{o}{.}\PYG{n}{g}\PYG{o}{.}\PYG{p}{,}

    \PYG{n}{docker} \PYG{n}{tag} \PYG{n}{apps}\PYG{o}{\PYGZhy{}}\PYG{n}{classification}\PYG{o}{\PYGZhy{}}\PYG{n}{orchestrator}\PYG{p}{:}\PYG{n}{test}  \PYG{n}{mcdmpdemoregistry}\PYG{o}{.}\PYG{n}{azurecr}\PYG{o}{.}\PYG{n}{io}\PYG{o}{/}\PYG{n}{apps}\PYG{o}{\PYGZhy{}}\PYG{n}{classification}\PYG{o}{\PYGZhy{}}\PYG{n}{orchestrator}\PYG{p}{:}\PYG{n}{test}
\end{sphinxVerbatim}

\item {} 
Push the image to repository using the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
    \PYG{n}{docker} \PYG{n}{push} \PYG{o}{\PYGZlt{}} \PYG{n}{repository} \PYG{o}{\PYGZgt{}}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{service}\PYG{o}{\PYGZhy{}}\PYG{n}{name}\PYG{o}{\PYGZgt{}}\PYG{p}{:}\PYG{o}{\PYGZlt{}}\PYG{n}{tag}\PYG{o}{\PYGZgt{}}

\PYG{n}{For} \PYG{n}{e}\PYG{o}{.}\PYG{n}{g}\PYG{o}{.}\PYG{p}{,}

    \PYG{n}{docker} \PYG{n}{push}  \PYG{n}{mcdmpdemoregistry}\PYG{o}{.}\PYG{n}{azurecr}\PYG{o}{.}\PYG{n}{io}\PYG{o}{/}\PYG{n}{apps}\PYG{o}{\PYGZhy{}}\PYG{n}{classification}\PYG{o}{\PYGZhy{}}\PYG{n}{orchestrator}\PYG{p}{:}\PYG{n}{test}
\end{sphinxVerbatim}

\item {} 
From deployment/helm folder run the following commands to deploy the service:
\begin{itemize}
\item {} 
Verify correct repository and tag are applied in deployment.yaml using the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
  \PYG{n}{helm} \PYG{n}{install} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{debug} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{dry}\PYG{o}{\PYGZhy{}}\PYG{n}{run} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{set} \PYG{n}{image}\PYG{o}{.}\PYG{n}{repository}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{repository}\PYG{o}{\PYGZgt{}}\PYG{o}{/} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{set} \PYG{n}{image}\PYG{o}{.}\PYG{n}{tag}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{tag}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{service}\PYG{o}{\PYGZhy{}}\PYG{n}{name}\PYG{o}{\PYGZgt{}}\PYG{o}{/}

\PYG{n}{For} \PYG{n}{e}\PYG{o}{.}\PYG{n}{g}\PYG{o}{.}\PYG{p}{,}

  \PYG{n}{helm} \PYG{n}{install} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{debug} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{dry}\PYG{o}{\PYGZhy{}}\PYG{n}{run} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{set} \PYG{n}{image}\PYG{o}{.}\PYG{n}{repository}\PYG{o}{=}\PYG{n}{mcdmpdemoregistry}\PYG{o}{.}\PYG{n}{azurecr}\PYG{o}{.}\PYG{n}{io}\PYG{o}{/} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{set} \PYG{n}{image}\PYG{o}{.}\PYG{n}{tag}\PYG{o}{=}\PYG{n}{test} \PYG{n}{apps}\PYG{o}{\PYGZhy{}}\PYG{n}{classification}\PYG{o}{\PYGZhy{}}\PYG{n}{orchestrator}\PYG{o}{/}
\end{sphinxVerbatim}

\item {} 
Install the service using command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
  \PYG{n}{helm} \PYG{n}{install} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{namespace}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{namespace}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{name}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{service}\PYG{o}{\PYGZhy{}}\PYG{n}{name}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{set} \PYG{n}{image}\PYG{o}{.}\PYG{n}{repository}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{repository}\PYG{o}{\PYGZgt{}}\PYG{o}{/} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{set} \PYG{n}{image}\PYG{o}{.}\PYG{n}{tag}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{tag}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{service}\PYG{o}{\PYGZhy{}}\PYG{n}{name}\PYG{o}{\PYGZgt{}}

\PYG{n}{For} \PYG{n}{e}\PYG{o}{.}\PYG{n}{g}\PYG{o}{.}\PYG{p}{,}

  \PYG{n}{helm} \PYG{n}{install} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{namespace}\PYG{o}{=}\PYG{n}{platform} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{name}\PYG{o}{=}\PYG{n}{apps}\PYG{o}{\PYGZhy{}}\PYG{n}{classification}\PYG{o}{\PYGZhy{}}\PYG{n}{orchestrator} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{set} \PYG{n}{image}\PYG{o}{.}\PYG{n}{repository}\PYG{o}{=}\PYG{n}{mcdmpdemoregistry}\PYG{o}{.}\PYG{n}{azurecr}\PYG{o}{.}\PYG{n}{io}\PYG{o}{/} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{set} \PYG{n}{image}\PYG{o}{.}\PYG{n}{tag}\PYG{o}{=}\PYG{n}{test} \PYG{n}{apps}\PYG{o}{\PYGZhy{}}\PYG{n}{classification}\PYG{o}{\PYGZhy{}}\PYG{n}{orchestrator}\PYG{o}{/}
\end{sphinxVerbatim}

\end{itemize}

\item {} 
Pod is up and running with infinite sleep. You can exec into pod and execute the jar, script, etc., within it. Also new jars, files, scripts, etc., can be copied into the pod.

\end{itemize}

\item {} 
Patch for terminal Dimensions not supported inside Pods

Many a times, when accessing a Pod say Kafka or Loom Connector Service, the pod doesn’t use the entire terminal dimension. The text gets wrapped around or overlapped or only few lines are shown while editing a file inside pod using vi editor.

The following script can be used to get rid of the problem for that instance.
\begin{itemize}
\item {} 
In your machine, create a file, say file with the name exec\_script.sh

\item {} 
Update the file with the following commands:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
if [ \PYGZdq{}\PYGZdl{}1\PYGZdq{} = \PYGZdq{}\PYGZdq{} ]; then
  echo \PYGZdq{}Usage: bash exec\PYGZus{}script.sh \PYGZlt{}pod\PYGZus{}name\PYGZgt{}\PYGZdq{}
  exit 1
fi

COLUMNS={}`tput cols{}`
LINES={}`tput lines{}`
TERM=xterm
kubectl \PYGZhy{}\PYGZhy{}namespace=platform exec \PYGZhy{}i \PYGZhy{}t \PYGZdl{}1 env COLUMNS=\PYGZdl{}COLUMNS LINES=\PYGZdl{}LINES TERM=\PYGZdl{}TERM bash
\end{sphinxVerbatim}

\item {} 
To get inside the pod instead of using:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{kubectl} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{namespace}\PYG{o}{=}\PYG{n}{platform} \PYG{o}{\PYGZhy{}}\PYG{n}{it} \PYG{o}{\PYGZlt{}}\PYG{n}{pod\PYGZus{}name}\PYG{o}{\PYGZgt{}} \PYG{n}{bash}
\end{sphinxVerbatim}

use the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{bash} \PYG{n}{exec\PYGZus{}script}\PYG{o}{.}\PYG{n}{sh} \PYG{o}{\PYGZlt{}}\PYG{n}{pod\PYGZus{}name}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

\end{itemize}

\end{enumerate}


\section{Troubleshooting Loom networking issues}
\label{\detokenize{loom_installation_guide:troubleshooting-loom-networking-issues}}
TBD


\section{Control plane Issues}
\label{\detokenize{loom_installation_guide:control-plane-issues}}
TBD


\section{Data plane Issues}
\label{\detokenize{loom_installation_guide:data-plane-issues}}
TBD


\section{Message flow between data plane/control plane}
\label{\detokenize{loom_installation_guide:message-flow-between-data-plane-control-plane}}
TBD


\section{Tenant deployment issues}
\label{\detokenize{loom_installation_guide:tenant-deployment-issues}}
TBD


\section{Security Issues}
\label{\detokenize{loom_installation_guide:security-issues}}
TBD


\section{Issues related to Loom logs, Access logs}
\label{\detokenize{loom_installation_guide:issues-related-to-loom-logs-access-logs}}
TBD


\section{Moving to different availability set}
\label{\detokenize{loom_installation_guide:moving-to-different-availability-set}}
TBD


\section{Issues related to sluggish Loom Application response}
\label{\detokenize{loom_installation_guide:issues-related-to-sluggish-loom-application-response}}
TBD


\section{Issues related to Loom Metrics}
\label{\detokenize{loom_installation_guide:issues-related-to-loom-metrics}}
TBD


\section{Issues related to System Load}
\label{\detokenize{loom_installation_guide:issues-related-to-system-load}}
TBD


\bigskip\hrule\bigskip



\chapter{Deployment FAQ}
\label{\detokenize{loom_installation_guide:deployment-faq}}
This is a FAQ document template which will cover generic Q/A related to Loom deployment.  Note this will cover all deployment issues which are not specific to a particular deployment model.


\section{Question A: Related to any type of Loom deployment}
\label{\detokenize{loom_installation_guide:question-a-related-to-any-type-of-loom-deployment}}
TBD



\renewcommand{\indexname}{Index}
\printindex
\end{document}